{
  "name": "sentence-tokenizer",
  "version": "0.0.0",
  "description": "Tokenize paragraphs into sentences, and smaller tokens.",
  "main": "lib/tokenizer.js",
  "scripts": {
    "test": "make test"
  },
  "repository": "",
  "keywords": [
    "tokenizer",
    "sentence"
  ],
  "author": "Fran√ßois Parmentier",
  "license": "MIT",
  "readmeFilename": "README.md",
  "dependencies": {
    "debug": "*",
    "sugar": "1.3.x"
  },
  "devDependencies": {
    "mocha": "1.7.x"
  }
}
